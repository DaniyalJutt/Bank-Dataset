{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91719,"databundleVersionId":12937777,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/daniyalatta/bank-term-deposit-subscription-prediction-dataset?scriptVersionId=258323009\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:32:43.753832Z","iopub.execute_input":"2025-08-21T11:32:43.754122Z","iopub.status.idle":"2025-08-21T11:32:44.019215Z","shell.execute_reply.started":"2025-08-21T11:32:43.7541Z","shell.execute_reply":"2025-08-21T11:32:44.018631Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"font-family: 'Segoe UI', Arial, sans-serif; padding: 20px; background-color: #f8f9fa; border-radius: 8px; border: 1px solid #e2e6ea; color: #343a40;\">\n    <h1 style=\"color: #007bff; font-weight: 700; border-bottom: 2px solid #007bff; padding-bottom: 10px; margin-bottom: 10px;\">\n        Bank Term Deposit Subscription Prediction\n    </h1>\n    <h3 style=\"color: #5a6268; font-weight: 500; margin-top: 0;\">\n       Predict whether a client will subscribe to a bank term deposit (target variable: y) using advanced machine learning techniques.\n    </h3>\n\n<div style=\"margin-top: 20px; font-size: 14px;\">\n    <strong>Author:</strong> Daniyal Atta<br>\n    <strong>Date:</strong> August 20, 2025<br>\n    <strong>Dataset:</strong> Bank Term Deposit Subscription Prediction Dataset (Train & Test CSV)\n</div>\n\n<hr style=\"border-top: 1px dashed #ced4da; margin: 25px 0;\">\n\n<div style=\"font-size: 16px;\">\n    <h4 style=\"color: #007bff; margin-top: 0;\">Notebook Overview</h4>\n    <ol padding-left: 0;\">\n        <li style=\"margin-bottom: 8px;\"><b>Importing Libraries & Environment Setup:</b> Load modern Python ML libraries for data processing, visualization, model building, and evaluation.</li>\n        <li style=\"margin-bottom: 8px;\"><b>Data Loading & Wrangling:</b> Load train and test datasets, perform advanced feature engineering including interaction features, cyclical transformations, log transformations, and derived binary indicators.</li>\n        <li style=\"margin-bottom: 8px;\"><b>Exploratory Data Analysis (EDA):</b> Analyze feature distributions, correlations, and target balance to guide preprocessing and model design.</li>\n        <li style=\"margin-bottom: 8px;\"><b>Advanced 3D Visualizations (GPU-Accelerated):</b> \n<ul style=\"font-family: 'Segoe UI', Arial, sans-serif; color: #343a40; font-size: 14px;\">\n  <li><strong>3D Scatter Plot:</strong> Visualize relationships between key numerical features and the target variable.</li>\n  <li><strong>3D Surface Plot:</strong> Explore predicted probabilities from a GPU-accelerated classifier across two key features.</li>\n  <li><strong>3D PCA Projection:</strong> Reduce high-dimensional data into 3 principal components for interactive exploration.</li>\n</ul></li>\n         <li style=\"margin-bottom: 8px;\"><b>Preprocessing & Pipeline Design:</b> Encode categorical variables, scale numerical features, and create modular pipelines to prevent leakage and ensure reproducibility.</li>\n         <li style=\"margin-bottom: 8px;\"><b>Modeling:</b> Train robust gradient boosting models including CatBoost, XGBoost, and LightGBM with optimized hyperparameters, ensuring high predictive performance.</li>\n         <li style=\"margin-bottom: 8px;\"><b>Evaluation:</b> Use ROC AUC as the primary metric, along with confusion matrices and classification reports to understand model strengths and weaknesses.</li>\n         <li style=\"margin-bottom: 8px;\"><b>Submission Generation:</b>  Produce probability-based predictions for the test dataset in the required competition format (id, y) for Kaggle submission.</li>\n        <li style=\"margin-bottom: 0;\"><b>Conclusion & Insights:</b> Summarize findings, highlight feature importance, model performance, and suggest potential improvements or next steps for deployment.</li>\n    </ol>\n</div>\n</div>\n\n","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #f0f8ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\n Cell 1: Libraries & Environment Setup\n</h2>","metadata":{}},{"cell_type":"code","source":"# ------------------ Libraries & Environment ------------------ #\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom category_encoders import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom tqdm.notebook import tqdm\nimport warnings\n\nwarnings.simplefilter(\"ignore\")\n\nprint(\"Environment Ready âœ…\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:32:49.051998Z","iopub.execute_input":"2025-08-21T11:32:49.052772Z","iopub.status.idle":"2025-08-21T11:32:55.119183Z","shell.execute_reply.started":"2025-08-21T11:32:49.052749Z","shell.execute_reply":"2025-08-21T11:32:55.118273Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #f0f8ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\nCell 2: Data Loading\n</h2>","metadata":{}},{"cell_type":"code","source":"# ------------------ Data Loading ------------------ #\ntrain_path = \"/kaggle/input/playground-series-s5e8/train.csv\"\ntest_path  = \"/kaggle/input/playground-series-s5e8/test.csv\"\n\ntrain_df = pd.read_csv(train_path, index_col=\"id\")\ntest_df  = pd.read_csv(test_path, index_col=\"id\")\n\nprint(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:32:57.42354Z","iopub.execute_input":"2025-08-21T11:32:57.424513Z","iopub.status.idle":"2025-08-21T11:32:59.86045Z","shell.execute_reply.started":"2025-08-21T11:32:57.424489Z","shell.execute_reply":"2025-08-21T11:32:59.859828Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #f0f8ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\n  Cell 3: Feature Engineering / Wrangling\n</h2>","metadata":{}},{"cell_type":"code","source":"# ------------------ Feature Engineering ------------------ #\ndef wrangle(df):\n    # Interaction Features\n    df[\"questions\"] = df[\"default\"] + \" \" + df[\"housing\"] + \" \" + df[\"contact\"]\n    df[\"status\"]    = df[\"job\"] + \" \" + df[\"education\"] + \" \" + df[\"marital\"]\n    df[\"intellect\"] = df[\"job\"] + \" \" + df[\"education\"]\n    \n    # Cyclical Duration\n    df[\"min_duration_sin\"] = np.sin(df[\"duration\"] / 60)\n    df[\"min_duration_cos\"] = np.cos(df[\"duration\"] / 60)\n    \n    # Date feature\n    df[\"date\"] = df[\"day\"].astype(str) + \" \" + df[\"month\"]\n    \n    # Binary Feature\n    df['contacted_before'] = (df['pdays'] != -1).astype(int)\n    \n    # Log transformation\n    df['balance_log'] = np.log1p(df['balance'].clip(lower=0))\n    \n    # Drop redundant\n    if 'pdays' in df.columns:\n        df = df.drop(columns=\"pdays\")\n    \n    return df\n\ntrain_df = wrangle(train_df)\ntest_df  = wrangle(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:32:59.861546Z","iopub.execute_input":"2025-08-21T11:32:59.861837Z","iopub.status.idle":"2025-08-21T11:33:01.530444Z","shell.execute_reply.started":"2025-08-21T11:32:59.861818Z","shell.execute_reply":"2025-08-21T11:33:01.52958Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #f0f8ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\n  Cell 4: Exploratory Data Analysis\n</h2>","metadata":{}},{"cell_type":"code","source":"# ------------------ EDA ------------------ #\n# Target distribution\nplt.figure(figsize=(5,4))\ntrain_df[\"y\"].value_counts(normalize=True).plot(kind='bar', color='skyblue')\nplt.title(\"Target Distribution\")\nplt.xlabel(\"y\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n# Correlation heatmap for numerical features\nplt.figure(figsize=(10,6))\nsns.heatmap(train_df.select_dtypes(\"number\").drop(columns=\"y\").corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:33:01.531331Z","iopub.execute_input":"2025-08-21T11:33:01.531607Z","iopub.status.idle":"2025-08-21T11:33:02.655693Z","shell.execute_reply.started":"2025-08-21T11:33:01.531562Z","shell.execute_reply":"2025-08-21T11:33:02.654934Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"font-family: 'Segoe UI', Arial, sans-serif; padding: 20px; background-color: #f8f9fa; border-radius: 8px; border: 1px solid #e2e6ea; color: #343a40;\">\n<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #e6f0ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\n  Cell 5: Advanced 3D Visualizations (GPU-Accelerated)\n</h2>\n\n<p style=\"font-family: 'Segoe UI', Arial, sans-serif; color: #343a40; line-height: 1.6; font-size: 14px;\">\nThis section demonstrates advanced, interactive 3D visualizations of the Bank Term Deposit dataset. Using GPU-accelerated libraries such as <strong>cuDF</strong> and <strong>cuML</strong>, we efficiently process large datasets on a T4x2 GPU environment. The visualizations include:\n</p>\n\n<ul style=\"font-family: 'Segoe UI', Arial, sans-serif; color: #343a40; font-size: 14px;\">\n  <li><strong>3D Scatter Plot:</strong> Visualize relationships between key numerical features and the target variable.</li>\n  <li><strong>3D Surface Plot:</strong> Explore predicted probabilities from a GPU-accelerated classifier across two key features.</li>\n  <li><strong>3D PCA Projection:</strong> Reduce high-dimensional data into 3 principal components for interactive exploration.</li>\n</ul>\n","metadata":{}},{"cell_type":"code","source":"# Make sure RAPIDS is installed (cuDF, cuML)\n# import cudf\n# import cuml\nimport cupy as cp\nimport cuml\nfrom cuml.preprocessing import StandardScaler as cuStandardScaler\nfrom cuml.decomposition import PCA as cuPCA\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport pandas as pd\nimport numpy as np\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:33:02.656809Z","iopub.execute_input":"2025-08-21T11:33:02.657033Z","iopub.status.idle":"2025-08-21T11:33:08.766498Z","shell.execute_reply.started":"2025-08-21T11:33:02.657016Z","shell.execute_reply":"2025-08-21T11:33:08.765934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\nimport cudf\n\n# Convert pandas DataFrame to cuDF for GPU acceleration\ngdf = cudf.DataFrame.from_pandas(train_df)\n\n# Ensure target is numeric\ngdf['y'] = gdf['y'].astype('int32')\n\n# Sample dataset to reduce size for plotting\nsample_size = 5000  # adjust as needed\ngdf_sample = gdf.sample(n=sample_size, random_state=42)\n\n# Convert to pandas for Plotly\npdf = gdf_sample[['balance','duration','campaign','y','previous','age','job','education']].to_pandas()\n\n# 3D Scatter\nfig = px.scatter_3d(\n    pdf,\n    x='balance',\n    y='duration',\n    z='campaign',\n    color='y',\n    size='previous',\n    opacity=0.8,\n    hover_data=['age','job','education'],\n    color_continuous_scale=px.colors.sequential.Viridis\n)\n\n# Layout adjustments\nfig.update_layout(\n    title=\"3D Scatter of Top Features vs Target\",\n    scene=dict(xaxis_title='Balance', yaxis_title='Duration', zaxis_title='Campaign'),\n    paper_bgcolor='rgb(240,248,255)',\n    plot_bgcolor='rgb(240,248,255)',\n    font=dict(color='black')\n)\n\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:35:07.953461Z","iopub.execute_input":"2025-08-21T11:35:07.953928Z","iopub.status.idle":"2025-08-21T11:35:11.344753Z","shell.execute_reply.started":"2025-08-21T11:35:07.953904Z","shell.execute_reply":"2025-08-21T11:35:11.344023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from cuml.ensemble import RandomForestClassifier as cuRF\nimport cupy as cp\nimport plotly.graph_objects as go\n\n# Features and target\nfeatures = ['balance', 'duration']\nX_gpu = gdf[features].astype('float32')\ny_gpu = gdf['y'].astype('int32')\n\n# Train GPU RandomForest\nmodel = cuRF(n_estimators=200, max_depth=8, random_state=42)\nmodel.fit(X_gpu, y_gpu)\n\n# Create mesh grid\nx_range = cp.linspace(X_gpu[features[0]].min(), X_gpu[features[0]].max(), 50)\ny_range = cp.linspace(X_gpu[features[1]].min(), X_gpu[features[1]].max(), 50)\nxx, yy = cp.meshgrid(x_range, y_range)\ngrid = cp.column_stack([xx.ravel(), yy.ravel()])\n\n# Predict probabilities\npred_prob_gpu = model.predict_proba(grid)  # Returns cupy array\n# Select probability for class 1\npred_prob = pred_prob_gpu[:, 1].reshape(xx.shape)  # No .get() needed if already cupy\n\n# Move to CPU for Plotly\npred_prob_cpu = cp.asnumpy(pred_prob)\nxx_cpu = cp.asnumpy(xx)\nyy_cpu = cp.asnumpy(yy)\n\n# Plot 3D surface\nfig = go.Figure(data=[go.Surface(z=pred_prob_cpu, x=xx_cpu, y=yy_cpu)])\nfig.update_layout(\n    title=\"3D Surface: Predicted Probability by Features\",\n    scene=dict(\n        xaxis_title=features[0],\n        yaxis_title=features[1],\n        zaxis_title=\"Predicted Probability\"\n    )\n)\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:35:17.21655Z","iopub.execute_input":"2025-08-21T11:35:17.217536Z","iopub.status.idle":"2025-08-21T11:35:22.63405Z","shell.execute_reply.started":"2025-08-21T11:35:17.217504Z","shell.execute_reply":"2025-08-21T11:35:22.633357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cudf\nimport cupy as cp\nfrom cuml.preprocessing import StandardScaler as cuStandardScaler\nfrom cuml.decomposition import PCA as cuPCA\nimport plotly.express as px\nimport pandas as pd\n\n# Ensure numeric columns are float32 for cuML\nnumeric_cols = gdf.select_dtypes(include=['int64','float64']).columns\nX_numeric = gdf[numeric_cols].astype('float32')\n\n# Convert to cupy array for GPU\nX_gpu = X_numeric.to_cupy()\n\n# Standardize on GPU\nscaler = cuStandardScaler()\nX_scaled = scaler.fit_transform(X_gpu)\n\n# PCA to 3 components\npca = cuPCA(n_components=3)\nX_pca = pca.fit_transform(X_scaled)\n\n# Convert to pandas for Plotly\npca_df = pd.DataFrame(cp.asnumpy(X_pca), columns=['PC1','PC2','PC3'])\npca_df['y'] = gdf['y'].astype(int).to_pandas()\n\n# Sample to reduce plot size\npca_df_sample = pca_df.sample(n=5000, random_state=42)\n\n# 3D Scatter\nfig = px.scatter_3d(\n    pca_df_sample,\n    x='PC1', y='PC2', z='PC3',\n    color='y',\n    opacity=0.7,\n    title=\"3D PCA Projection of Dataset\"\n)\nfig.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:35:22.635237Z","iopub.execute_input":"2025-08-21T11:35:22.63584Z","iopub.status.idle":"2025-08-21T11:35:31.811426Z","shell.execute_reply.started":"2025-08-21T11:35:22.635819Z","shell.execute_reply":"2025-08-21T11:35:31.810623Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #f0f8ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\n  Cell 6: Train-Test Split\n</h2>","metadata":{}},{"cell_type":"code","source":"# ------------------ Train-Test Split ------------------ #\ntarget = \"y\"\nX = train_df.drop(columns=target)\ny = train_df[target]\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\nprint(f\"Train: {X_train.shape}, Validation: {X_val.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:35:31.812509Z","iopub.execute_input":"2025-08-21T11:35:31.812839Z","iopub.status.idle":"2025-08-21T11:35:32.591629Z","shell.execute_reply.started":"2025-08-21T11:35:31.812805Z","shell.execute_reply":"2025-08-21T11:35:32.590943Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #f0f8ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\n  Cell 7: Model Definitions & Hyperparameters\n</h2>\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import HistGradientBoostingClassifier\n\n# ------------------ Models & Hyperparameters ------------------ #\nxgb_params = {\n    'n_estimators': 2805, 'learning_rate': 0.03, 'max_depth': 10, \n    'subsample': 0.92, 'colsample_bytree': 0.5, 'random_state': 42\n}\n\ncat_params = {\n    'iterations': 976, 'learning_rate': 0.094, 'depth': 10, \n    'bagging_temperature': 2.79, 'random_state': 42, 'verbose': 0\n}\n\nhgb_params = {\n    'max_iter': 1000,\n    'max_depth': 10,\n    'learning_rate': 0.05,\n    'min_samples_leaf': 20,\n    'max_bins': 255,\n    'random_state': 42\n}\n\nmodels = [\n    HistGradientBoostingClassifier(**hgb_params),\n    CatBoostClassifier(**cat_params),\n    XGBClassifier(**xgb_params),\n    \n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:35:34.820135Z","iopub.execute_input":"2025-08-21T11:35:34.820719Z","iopub.status.idle":"2025-08-21T11:35:34.826983Z","shell.execute_reply.started":"2025-08-21T11:35:34.820696Z","shell.execute_reply":"2025-08-21T11:35:34.826267Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #f0f8ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\n  Cell 8: Training, Evaluation & Submission\n</h2>\n","metadata":{}},{"cell_type":"code","source":"# ------------------ Robust Training & Evaluation ------------------ #\nfrom sklearn.compose import ColumnTransformer\n\ndef train_evaluate_submit(models, X_train, X_val, y_train, y_val, test_df):\n    results = {}\n    \n    # Identify categorical and numeric columns\n    cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n    num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n    \n    # Preprocessor\n    preprocessor = ColumnTransformer([\n        ('cat', OneHotEncoder(use_cat_names=True, handle_unknown='ignore'), cat_cols),\n        ('num', 'passthrough', num_cols)\n    ])\n    \n    for model in tqdm(models, desc=\"Training Models\"):\n        # Full pipeline: encoding + scaling + model\n        pipeline = make_pipeline(\n            preprocessor,\n            StandardScaler(with_mean=False),  # Avoid issues with sparse matrix\n            model\n        )\n        \n        # Fit\n        pipeline.fit(X_train, y_train)\n        \n        # Validation predictions\n        val_pred_prob = pipeline.predict_proba(X_val)[:,1]\n        val_pred_class = pipeline.predict(X_val)\n        \n        # Metrics\n        roc_score = roc_auc_score(y_val, val_pred_prob)\n        print(f\"\\nModel: {model.__class__.__name__}\")\n        print(f\"ROC AUC Score: {roc_score:.4f}\")\n        print(classification_report(y_val, val_pred_class))\n        \n        # Confusion matrix\n        cm = confusion_matrix(y_val, val_pred_class, labels=[0,1])\n        disp = ConfusionMatrixDisplay(cm, display_labels=[0,1])\n        disp.plot(cmap=plt.cm.Blues)\n        plt.title(f\"Confusion Matrix - {model.__class__.__name__}\")\n        plt.show()\n        \n        # Submission predictions\n        test_pred_prob = pipeline.predict_proba(test_df)[:,1]\n        sub_df = pd.DataFrame({\"y\": test_pred_prob}, index=test_df.index)\n        sub_df.to_csv(f\"{model.__class__.__name__}_submission.csv\", index=True)\n        print(f\"Submission file saved: {model.__class__.__name__}_submission.csv\")\n        \n        results[model.__class__.__name__] = roc_score\n    \n    return pd.DataFrame.from_dict(results, orient='index', columns=[\"ROC_AUC\"]).sort_values(\"ROC_AUC\", ascending=False)\n\n# Run training & submission\nscore_df = train_evaluate_submit(models, X_train, X_val, y_train, y_val, test_df)\nscore_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T11:35:42.867048Z","iopub.execute_input":"2025-08-21T11:35:42.867283Z","iopub.status.idle":"2025-08-21T12:01:54.739998Z","shell.execute_reply.started":"2025-08-21T11:35:42.867267Z","shell.execute_reply":"2025-08-21T12:01:54.739327Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div style=\"font-family: 'Segoe UI', Arial, sans-serif; padding: 20px; background-color: #f8f9fa; border-radius: 8px; border: 1px solid #e2e6ea; color: #343a40;\">\n<h2 style=\"font-family: 'Segoe UI', Arial, sans-serif; background-color: #f0f8ff; color: #004085; padding: 12px 15px; margin-top: 30px; border-left: 5px solid #007bff; border-radius: 4px; font-weight: 600;\">\n  Conclusion\n</h2>\n\n<p style=\"font-family: 'Segoe UI', Arial, sans-serif; color: #343a40; line-height: 1.6; font-size: 14px;\">\nIn this notebook, we successfully developed a predictive model to identify clients likely to subscribe to a bank term deposit. Through comprehensive exploratory data analysis and advanced preprocessing steps, we trained multiple classification algorithms. Among them, the <strong>CatBoost Classifier</strong> emerged as the top performer based on key evaluation metrics such as <strong>AUC-ROC</strong> and <strong>Accuracy</strong>.\n</p>\n\n<p style=\"font-family: 'Segoe UI', Arial, sans-serif; color: #343a40; line-height: 1.6; font-size: 14px;\">\nWhile the current model provides a strong foundation for a predictive system, there is always room for improvement. Future iterations of this project will focus on <strong>hyperparameter optimization</strong> to further enhance performance. We plan to leverage advanced optimization frameworks such as <strong>Optuna</strong> to fine-tune model parameters and achieve a more robust and accurate solution. Additionally, we aim to explore more sophisticated <strong>feature engineering techniques</strong> to provide our model with even greater predictive power and improve its real-world applicability.\n</p>\n</div>","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}